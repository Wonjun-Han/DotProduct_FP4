import cocotb
from cocotb.triggers import RisingEdge
from cocotb.clock import Clock
import random
import struct
import math
from typing import Tuple, List, Optional
from cocotb.triggers import ReadOnly

# =============================================================================
# Configuration
# =============================================================================
PIPELINE_LATENCY = 12  # Exactly 12 cycles for first result
NUM_TRIALS_SINGLE = 50
NUM_TRIALS_CONTINUOUS = 20
NUM_THROUGHPUT_TRANSACTIONS = 15

# =============================================================================
# Utility Functions
# =============================================================================

def decode_mxfp4(val: int) -> float:
    """MXFP4 decoder: [s | e1 e0 | m] (4 bits total)"""
    s = (val >> 3) & 0x1
    e = (val >> 1) & 0x3
    m = val & 0x1
    if e == 0:
        return (-1.0 if s else 1.0) * (m / 2.0) if m != 0 else 0.0
    else:
        return (-1.0 if s else 1.0) * (1.0 + m / 2.0) * (2.0 ** (e - 1))

def bits_to_float(b: int) -> float:
    return struct.unpack('>f', struct.pack('>I', b))[0]

def get_fp32_fields(bits: int):
    sign     = (bits >> 31) & 0x1
    exponent = (bits >> 23) & 0xFF
    mantissa = bits & 0x7FFFFF
    return sign, exponent, mantissa

# --- X/Z-safe í”Œë« ì‹ í˜¸ ë¦¬ë” (flattenëœ í¬íŠ¸ëª… ìš°ì„ )
def _read_flat_signal(dut, name: str) -> Tuple[bool, Optional[int]]:
    h = getattr(dut, name, None)
    if h is None:
        return False, None
    v = h.value
    bs = getattr(v, "binstr", None)
    if bs is not None and ('x' in bs.lower() or 'z' in bs.lower()):
        return False, None
    try:
        return True, int(v)
    except Exception:
        return False, None

def read_fp32(dut, i: int) -> Tuple[int, int, int]:
    """FP32 í•„ë“œ ì½ê¸°: í”Œë« ì‹ í˜¸(io_out_*_*) ìš°ì„ , ì‹¤íŒ¨ ì‹œ Bundle ê²½ë¡œ(io.out[i].*) ì‹œë„"""
    ok_s, s = _read_flat_signal(dut, f"io_out_{i}_sign")
    ok_e, e = _read_flat_signal(dut, f"io_out_{i}_exponent")
    ok_m, m = _read_flat_signal(dut, f"io_out_{i}_mantissa")
    if ok_s and ok_e and ok_m and s is not None and e is not None and m is not None:
        return int(s), int(e), int(m)

    # bundle fallback
    try:
        s2 = int(dut.io.out[i].sign.value)
        e2 = int(dut.io.out[i].exponent.value)
        m2 = int(dut.io.out[i].mantissa.value)
        return s2, e2, m2
    except Exception:
        raise RuntimeError(f"Output[{i}] has X/Z or is not accessible at this cycle")

FLT32_MAX = 3.4028234663852886e+38

def float_to_bits_safe(f: float) -> int:
    """Convert Python float to IEEE754 float32 bits safely"""
    if math.isnan(f):
        return 0x7FC00000  # qNaN
    sign_bit = 0x80000000 if math.copysign(1.0, f) < 0.0 else 0
    if math.isinf(f) or abs(f) > FLT32_MAX:
        return sign_bit | 0x7F800000  # Â±Inf
    try:
        return struct.unpack('>I', struct.pack('>f', f))[0]
    except OverflowError:
        return sign_bit | 0x7F800000

async def drive_zero_inputs(dut):
    """ì„ íƒ: ë¦¬ì…‹ ì „í›„ì— í•œ ë²ˆ 0ìœ¼ë¡œ ë°€ì–´ë„£ì–´ ì´ˆê¸° Xë¥¼ ì¤„ì„"""
    for i in range(256):
        getattr(dut, f"io_a_vec_{i}").value = 0
        getattr(dut, f"io_b_vec_{i}").value = 0
    for i in range(8):
        getattr(dut, f"io_a_scale_{i}").value = 0
        getattr(dut, f"io_b_scale_{i}").value = 0
    dut.io_depth.value = 0
    dut.io_dbg_token_in.value = 0  # â˜… í† í° ì…ë ¥ ì´ˆê¸°í™”

async def reset_dut(dut):
    """Reset DUT and clear pipeline"""
    await drive_zero_inputs(dut)
    dut.reset.value = 1
    await RisingEdge(dut.clock)
    await RisingEdge(dut.clock)
    dut.reset.value = 0
    await RisingEdge(dut.clock)
    # íŒŒì´í”„ ì™„ì „ ë¹„ìš°ê¸°
    for _ in range(PIPELINE_LATENCY + 3):
        await RisingEdge(dut.clock)

async def wait_outputs_stable(dut, max_wait_cycles=8):
    """ì¶œë ¥ì—ì„œ X/Zê°€ ì‚¬ë¼ì§ˆ ë•Œê¹Œì§€ ëŒ€ê¸°(ìµœëŒ€ max_wait_cycles ì‚¬ì´í´)"""
    for _ in range(max_wait_cycles + 1):
        try:
            for i in range(16):
                _ = read_fp32(dut, i)
            return True
        except RuntimeError:
            await RisingEdge(dut.clock)
    return False

# =============================================================================
# I/O Apply (Token í¬í•¨)
# =============================================================================
async def apply_inputs(dut, a_raw, b_raw, a_scale_raw, b_scale_raw, depth, token: int):
    for i in range(256):
        getattr(dut, f"io_a_vec_{i}").value = a_raw[i]
        getattr(dut, f"io_b_vec_{i}").value = b_raw[i]
    for i in range(8):
        getattr(dut, f"io_a_scale_{i}").value = a_scale_raw[i]
        getattr(dut, f"io_b_scale_{i}").value = b_scale_raw[i]
    dut.io_depth.value = depth
    dut.io_dbg_token_in.value = token & 0xFF  # â˜… í† í° ì£¼ì…

# =============================================================================
# Test Vector Class
# =============================================================================
class PipelineTestVector:
    """Complete test vector with expected outputs for all depths"""
    def __init__(self, a_raw, b_raw, a_scale_raw, b_scale_raw, depth, vector_id=0):
        self.a_raw = a_raw
        self.b_raw = b_raw
        self.a_scale_raw = a_scale_raw
        self.b_scale_raw = b_scale_raw
        self.depth = depth
        self.vector_id = vector_id
        self.scale_sums = [a + b - 254 for a, b in zip(a_scale_raw, b_scale_raw)]
        self.expected_outputs = self._compute_expected()

    def _compute_expected(self):
        expected = {}

        # â”€â”€ tile(32ê°œ) ë‹¨ìœ„ í•©/NaN ë¯¸ë¦¬ ê³„ì‚° (depth 6..8ìš©) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        tile_scaled_sum = [0.0] * 8
        tile_nan = [False] * 8
        for t in range(8):
            base = t * 32
            local_sum = 0.0
            for j in range(32):
                idx = base + j
                a_val = decode_mxfp4(self.a_raw[idx])
                b_val = decode_mxfp4(self.b_raw[idx])
                local_sum += a_val * b_val
            scale_exp_t = self.scale_sums[t]
            tile_scaled_sum[t] = math.ldexp(local_sum, scale_exp_t)
            tile_nan[t] = (self.a_scale_raw[t] == 255) or (self.b_scale_raw[t] == 255)

        # â”€â”€ ê¹Šì´ë³„ ê¸°ëŒ€ ì¶œë ¥ ê³„ì‚° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        for depth in range(9):
            total_out = 256 >> depth              # ì´ depthì—ì„œ ìƒì„±ë˜ëŠ” ì´ ê²°ê³¼ ìˆ˜
            output_count = min(total_out, 16)     # DUTê°€ ë‚´ë³´ë‚¼ 16ê°œ í•œë„
            products_per_output = 256 // total_out

            depth_outputs = []

            if depth <= 5:
                # ë¨¼ì € "ëª¨ë“  ê²°ê³¼(total_out)"ë¥¼ (g,k) => ê°’ ìœ¼ë¡œ ì „ë¶€ ê³„ì‚°í•´ ë°°ì—´ì— ë‹´ëŠ”ë‹¤.
                # g: 0..7 (8ê°œ ê·¸ë£¹), group_size: ê° ê·¸ë£¹ ë‚´ ê²°ê³¼ ê°œìˆ˜
                group_size = 32 >> depth
                all_vals_bits = []  # ê¸¸ì´ total_out

                for k in range(group_size):       # k-major (lane ìš°ì„ )
                    for g in range(8):            # ê° ê·¸ë£¹
                        # (g,k) ê°€ ìœ íš¨í•œ ê²½ìš°ì—ë§Œ ì¶”ê°€
                        if len(all_vals_bits) >= total_out:
                            break
                        base = g * 32 + k * products_per_output
                        local_sum = 0.0
                        for j in range(products_per_output):
                            idx = base + j
                            a_val = decode_mxfp4(self.a_raw[idx])
                            b_val = decode_mxfp4(self.b_raw[idx])
                            local_sum += a_val * b_val

                        if (self.a_scale_raw[g] == 255) or (self.b_scale_raw[g] == 255):
                            bits = 0x7FC00000  # qNaN
                        else:
                            scale_exp = self.scale_sums[g]
                            expected_float = math.ldexp(local_sum, scale_exp)
                            bits = float_to_bits_safe(expected_float)

                        all_vals_bits.append(bits)

                # total_out > 16ì´ë©´ k-major ìˆœì„œë¡œ ì•ì—ì„œ 16ê°œë§Œ ì±„íƒ
                chosen = all_vals_bits[:output_count]
                # ë‚˜ë¨¸ì§€ëŠ” 0ìœ¼ë¡œ íŒ¨ë”©
                depth_outputs = chosen + [0x00000000] * (16 - len(chosen))

            else:
                # depth 6..8: íƒ€ì¼ ê·¸ë£¹ í•©ì‚°
                if depth == 6:
                    groups = [[0,1], [2,3], [4,5], [6,7]]
                elif depth == 7:
                    groups = [[0,1,2,3], [4,5,6,7]]
                else:  # depth == 8
                    groups = [[0,1,2,3,4,5,6,7]]

                for i in range(16):
                    if i < len(groups):
                        tiles = groups[i]
                        if any(tile_nan[t] for t in tiles):
                            expected_bits = 0x7FC00000
                        else:
                            expected_float = sum(tile_scaled_sum[t] for t in tiles)
                            expected_bits = float_to_bits_safe(expected_float)
                    else:
                        expected_bits = 0x00000000
                    depth_outputs.append(expected_bits)

            expected[depth] = depth_outputs

        return expected

    def validate_result(self, dut, cycle_info=""):
        expected_outputs = self.expected_outputs[self.depth]
        errors = []
        for i in range(16):
            dut_sign, dut_exp, dut_man = read_fp32(dut, i)
            dut_bits = (dut_sign << 31) | (dut_exp << 23) | dut_man

            expected_bits = expected_outputs[i]
            expected_sign, expected_exp, expected_man = get_fp32_fields(expected_bits)

            # Allow small mantissa differences (Â±1) for rounding
            if (expected_sign != dut_sign or
                expected_exp != dut_exp or
                abs(expected_man - dut_man) > 1):
                errors.append({
                    'output_idx': i,
                    'expected': expected_bits,
                    'actual': dut_bits,
                    'expected_fields': (expected_sign, expected_exp, expected_man),
                    'actual_fields': (dut_sign, dut_exp, dut_man)
                })

        if errors:
            error_msg = f"\n[âŒ Vector {self.vector_id} | DEPTH {self.depth} | {cycle_info}]\n"
            for err in errors[:3]:
                error_msg += (
                    f"  Output {err['output_idx']}: "
                    f"Expected 0x{err['expected']:08X} "
                    f"Got 0x{err['actual']:08X}\n"
                )
            if len(errors) > 3:
                error_msg += f"  ... and {len(errors)-3} more errors\n"
            raise AssertionError(error_msg)
        return True

# =============================================================================
# Streaming helper with token check
# =============================================================================
async def inject_and_validate_stream(dut, test_vectors, tag=""):
    """
    ì „ ì‚¬ì´í´ì— ê±¸ì³ ì£¼ì…ê³¼ ê²€ì¦ì„ ì¸í„°ë¦¬ë¸Œë¡œ ìˆ˜í–‰.
    - ì‚¬ì´í´ k (1-base)ì—ì„œ:
      * k <= N ì´ë©´ kë²ˆì§¸ ì…ë ¥ ì£¼ì…(token=k)
      * k >= PIPELINE_LATENCY ì´ë©´ (k-PIPELINE_LATENCY+1)ë²ˆì§¸ ê²°ê³¼ ê²€ì¦
    """
    N = len(test_vectors)
    produced = 0
    total_cycles = N + PIPELINE_LATENCY - 1

    for cyc in range(total_cycles):  # cyc: 0..total_cycles-1, í‘œê¸°ìš© cycle = cyc+1
        # 1) ì£¼ì…
        if cyc < N:
            tv = test_vectors[cyc]
            await apply_inputs(dut, tv.a_raw, tv.b_raw, tv.a_scale_raw, tv.b_scale_raw, tv.depth, token=cyc+1)
            dut._log.info(f"â° Cycle {cyc+1}: Applied transaction {cyc+1}{(' ['+tag+']') if tag else ''}")


        # 2) í•œ ì‚¬ì´í´ ì§„í–‰
        await RisingEdge(dut.clock)

        # 3) ê²€ì¦ (ì›œì—… ì¢…ë£Œ ì´í›„ ë§¤ ì‚¬ì´í´ 1ê°œ ê²°ê³¼)
        if (cyc + 1) >= PIPELINE_LATENCY:
            idx = (cyc + 1) - PIPELINE_LATENCY  # 0-base
            ok = await wait_outputs_stable(dut, max_wait_cycles=0)
            assert ok, f"Outputs not stable before validation (index {idx+1}{(' '+tag) if tag else ''})"

            await ReadOnly()  # ì½¤ë¹„ë„¤ì´ì…”ë„ ë„¤íŠ¸ ì •ì°© ë³´ì¥

            # â˜… í† í° ì •í•© ì²´í¬: ì…€ë ‰í„°ê°€ ì˜¬ë°”ë¥¸ ê²½ë¡œ/íƒ€ì´ë°ì„ ë½‘ì•˜ëŠ”ì§€
            sel_tok = int(dut.io_dbg_token_sel.value)
            expect_tok = (cyc + 1 - PIPELINE_LATENCY + 1) & 0xFF  # ìš°ë¦¬ëŠ” ì£¼ì… token=cyc+1
            assert sel_tok == expect_tok, (
                f"[Token misalign] expected sel token {expect_tok}, got {sel_tok} at cycle {cyc+1}; "
                f"depth_s12={int(dut.io_depth.value)}"
            )

            # (ì˜µì…˜) ê²½ë¡œë³„ í† í° ë¡œê¹…
            path_toks = [int(getattr(dut, f"io_dbg_token_d_{k}").value) for k in range(9)]
            dut._log.info(f"Tokens@S12 paths={path_toks}, sel={sel_tok}, expect={expect_tok}")

            # ì‹¤ì œ ê²°ê³¼ ê²€ì¦
            test_vectors[idx].validate_result(dut, f"{tag} result {idx+1} at cycle {cyc+1}")
            produced += 1

    assert produced == N, f"Produced {produced}, expected {N}"
    return produced, total_cycles

def generate_random_scales():
    """Generate random but valid scale pairs"""
    a_scale_raw, b_scale_raw = [], []
    for _ in range(8):
        if random.random() < 0.05:  # 5% chance of NaN
            a_scale_raw.append(255)
            b_scale_raw.append(random.randint(0, 255))
        elif random.random() < 0.05:  # Another 5% chance of NaN
            a_scale_raw.append(random.randint(0, 254))
            b_scale_raw.append(255)
        else:
            total = random.randint(-100, 100)
            a = random.randint(50, 200)
            b = max(0, min(254, total + 254 - a))
            a_scale_raw.append(a)
            b_scale_raw.append(b)
    return a_scale_raw, b_scale_raw

# =============================================================================
# Tests
# =============================================================================

@cocotb.test()
async def test_pipeline_basic_latency(dut):
    """Test basic pipeline latency - single transaction"""
    cocotb.start_soon(Clock(dut.clock, 10, units='ns').start())
    await reset_dut(dut)

    dut._log.info("ğŸ§ª Testing basic pipeline latency (12 cycles)")

    # Single test vector
    a_raw = [random.randint(0, 15) for _ in range(256)]
    b_raw = [random.randint(0, 15) for _ in range(256)]
    a_scale_raw, b_scale_raw = generate_random_scales()
    depth = 4

    test_vector = PipelineTestVector(a_raw, b_raw, a_scale_raw, b_scale_raw, depth, 1)

    # Apply input at cycle 0 (token=1)
    await apply_inputs(dut, a_raw, b_raw, a_scale_raw, b_scale_raw, depth, token=1)
    dut._log.info("â° Cycle 0: Input applied")

    # Wait exactly 12 cycles
    for cycle in range(1, PIPELINE_LATENCY + 1):
        await RisingEdge(dut.clock)
        if cycle == PIPELINE_LATENCY:
            dut._log.info(f"â° Cycle {cycle}: Checking result")

    # ì•ˆì •í™” ëŒ€ê¸° í›„ ê²€ì¦
    ok = await wait_outputs_stable(dut, max_wait_cycles=4)
    assert ok, "Outputs still contain X/Z after latency window"

    # â˜… ì½¤ë¹„ ë„¤íŠ¸ ì •ì°© ë³´ì¥
    await ReadOnly()               # ë˜ëŠ”: await Timer(1, units='ps')

    # â˜… ì´ì œ í† í° ì½ê¸°
    sel_tok = int(dut.io_dbg_token_sel.value)
    assert sel_tok == 1, f"[Token misalign] expected 1, got {sel_tok} at cycle {PIPELINE_LATENCY}"

    test_vector.validate_result(dut, f"Cycle {PIPELINE_LATENCY}")

    dut._log.info("âœ… Basic latency test passed - exactly 12 cycles!")

@cocotb.test()
async def test_pipeline_continuous_throughput(dut):
    cocotb.start_soon(Clock(dut.clock, 10, units='ns').start())
    await reset_dut(dut)

    depth = 3
    N = NUM_THROUGHPUT_TRANSACTIONS
    tvs = []
    for i in range(N):
        a_raw = [random.randint(0, 15) for _ in range(256)]
        b_raw = [random.randint(0, 15) for _ in range(256)]
        a_scale_raw, b_scale_raw = generate_random_scales()
        tvs.append(PipelineTestVector(a_raw, b_raw, a_scale_raw, b_scale_raw, depth, i+1))

    dut._log.info(f"ğŸš€ Testing continuous throughput with {N} transactions")
    produced, total_cycles = await inject_and_validate_stream(dut, tvs, tag="Throughput")
    throughput = produced / total_cycles
    dut._log.info(f"âœ… Continuous throughput test passed!")
    dut._log.info(f"ğŸ“Š Achieved {produced} results in {total_cycles} cycles")
    dut._log.info(f"ğŸ“ˆ Throughput: {throughput:.3f} results/cycle (Target: 1.0 after warmup)")

@cocotb.test()
async def test_pipeline_all_depths_continuous(dut):
    cocotb.start_soon(Clock(dut.clock, 10, units='ns').start())
    await reset_dut(dut)

    for depth in range(9):
        dut._log.info(f"\nğŸ¯ ================ DEPTH {depth} CONTINUOUS PIPELINE TEST ================")
        N = NUM_TRIALS_CONTINUOUS
        tvs = []
        for i in range(N):
            a_raw = [random.randint(0, 15) for _ in range(256)]
            b_raw = [random.randint(0, 15) for _ in range(256)]
            a_scale_raw, b_scale_raw = generate_random_scales()
            tvs.append(PipelineTestVector(a_raw, b_raw, a_scale_raw, b_scale_raw, depth, i+1))

        produced, _ = await inject_and_validate_stream(dut, tvs, tag=f"Depth{depth}")
        assert produced == N, f"Depth {depth}: produced {produced}/{N}"
        dut._log.info(f"âœ… Depth {depth}: All {N} continuous vectors passed!")

    dut._log.info("\nğŸ† ALL DEPTHS CONTINUOUS PIPELINE TEST COMPLETED SUCCESSFULLY!")

@cocotb.test()
async def test_pipeline_mixed_depths(dut):
    cocotb.start_soon(Clock(dut.clock, 10, units='ns').start())
    await reset_dut(dut)

    dut._log.info("ğŸ”€ Testing mixed depth pipeline operation")
    depths = [0, 3, 6, 1, 8, 2, 7, 4, 5]
    tvs = []
    for i, depth in enumerate(depths):
        a_raw = [random.randint(0, 15) for _ in range(256)]
        b_raw = [random.randint(0, 15) for _ in range(256)]
        a_scale_raw, b_scale_raw = generate_random_scales()
        tvs.append(PipelineTestVector(a_raw, b_raw, a_scale_raw, b_scale_raw, depth, i+1))

    produced, _ = await inject_and_validate_stream(dut, tvs, tag="Mixed")
    assert produced == len(tvs)
    dut._log.info("âœ… Mixed depth pipeline test passed!")

@cocotb.test()
async def test_pipeline_stress_test(dut):
    cocotb.start_soon(Clock(dut.clock, 10, units='ns').start())
    await reset_dut(dut)

    dut._log.info("ğŸ’ª Pipeline stress test - rapid continuous operation")
    N = 50
    tvs = []
    for i in range(N):
        depth = random.randint(0, 8)
        a_raw = [random.randint(0, 15) for _ in range(256)]
        b_raw = [random.randint(0, 15) for _ in range(256)]
        a_scale_raw, b_scale_raw = generate_random_scales()
        tvs.append(PipelineTestVector(a_raw, b_raw, a_scale_raw, b_scale_raw, depth, i+1))

    produced, _ = await inject_and_validate_stream(dut, tvs, tag="Stress")
    assert produced == N, f"Stress test failed: {N - produced}/{N} errors"
    dut._log.info(f"âœ… Stress test passed: {produced} vectors processed successfully!")

# =============================================================================
# Final summary
# =============================================================================
@cocotb.test()
async def test_pipeline_final_summary(dut):
    cocotb.start_soon(Clock(dut.clock, 10, units='ns').start())
    await reset_dut(dut)

    dut._log.info("\n" + "="*80)
    dut._log.info("ğŸ COMPREHENSIVE PIPELINE VERIFICATION SUMMARY")
    dut._log.info("="*80)
    dut._log.info("âœ… Basic latency verification: 12 cycles exact")
    dut._log.info("âœ… Continuous throughput: 1 result/cycle after warmup")
    dut._log.info("âœ… All depth levels (0-8): Functional correctness")
    dut._log.info("âœ… Mixed depth operation: Dynamic switching")
    dut._log.info("âœ… Stress testing: High-frequency operation")
    dut._log.info("-" * 80)
    dut._log.info("ğŸ¯ DUT: p_TOP_Til_Dep_total_piped_CT")
    dut._log.info("ğŸ“ Architecture: 12-stage pipeline with depth-configurable accumulation")
    dut._log.info("ğŸ”§ Features: Scale-aware MXFP4 MAC with NaN propagation")
    dut._log.info("âš¡ Performance: True pipeline operation validated")
    dut._log.info("="*80)
    dut._log.info("ğŸ‰ ALL PIPELINE TESTS PASSED - READY FOR INTEGRATION!")
    dut._log.info("="*80)
