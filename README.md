# MXFP4/NVFP4 Pipelined Dot-Product Architecture

A high-performance, pipelined hardware implementation of MXFP4/NVFP4-based Multiply-Accumulate (MAC) logic for AI accelerators, designed in Chisel and test with cocotb.

---

## MXFP4

<img width="1516" height="847" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-08-04 á„‹á…©á„’á…® 4 19 38" src="https://github.com/user-attachments/assets/a2dba3c7-c750-4037-98be-a12f1fc80aff" />

<img width="2555" height="1417" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-08-13 á„‹á…©á„’á…® 8 53 50" src="https://github.com/user-attachments/assets/e09cfe3c-71f9-4ffd-ac38-10e175a91ceb" />


---

## NVFP4

<img width="2556" height="1420" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-08-13 á„‹á…©á„’á…® 8 53 34" src="https://github.com/user-attachments/assets/45569ecd-392e-4d57-b15e-38edb4632f6b" />

<img width="2555" height="1420" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2025-08-13 á„‹á…©á„’á…® 8 54 02" src="https://github.com/user-attachments/assets/ab8b63cb-a489-478d-8e29-0b4b12b5cb26" />



---



## ğŸ“Œ Overview

This project implements a **custom floating-point MAC unit** using the MXFP4 format from the OCP Microscaling (MX) specification. The system consists of the following key pipeline modules

- `FieldExtractor`: Parses 4-bit MXFP4 input into sign, exponent, mantissa
- `Multiplier`: Performs 256-element parallel MXFP4 Ã— MXFP4 multiplication
- `Convert`: Converts the Intermediate Data into IEEE-754 FP32 format (Configurable with Depth of Computation)
- `Adder Tree[SINT Format]`: Performs pipelined FP32 pairwise addition with rounding and normalization

All modules are optimized to run at higher Frequency than **1GHz clock**, with careful pipeline stage balancing.

---

## ğŸ’¡ MXFP4 Format

- **4-bit FP4 structure**: E2M1 (2-bit exponent, 1-bit mantissa, 1 sign)
- **Shared scale**: 8-bit E8M0 scaling factor is applied across groups of elements
- Supports both normal and subnormal representations

---

## ğŸ’¡ NVFP4 Format

> Introduced by NVIDIA in 2024, NVFP4 is a 4-bit floating-point format optimized for high-accuracy, low-precision inference.

- **Structure**: `E2M1` (4-bit total)
  - 1-bit sign
  - 2-bit exponent
  - 1-bit mantissa
- **Shared Scale**:
  - **Per-block**: 16-element group shares an FP8 scale (E4M3)
  - **Per-tensor**: Global FP32 (E8M23) normalization applied
- **No subnormal support**: Only normalized values are represented
- **Usage**: Accelerated by NVIDIA's **Blackwell Tensor Cores**
- **Design goal**: Achieve FP8-level accuracy with only 4-bit storage

---

### âœ… NVFP4 vs MXFP4 (Nvidia Developer Blogë¥¼ ì°¸ê³ .)

| Feature                   | **NVFP4**                                   | **MXFP4**                                |
|---------------------------|----------------------------------------------|-------------------------------------------|
| Format                    | E2M1                                         | E2M1                                      |
| Sign bit                  | 1                                            | 1                                         |
| Exponent bits             | 2                                            | 2                                         |
| Mantissa bits             | 1                                            | 1                                         |
| Subnormal support         | âœ… Yes                                       | âœ… Yes                                    |
| Block size (scale sharing)| 16                                           | 32                                        |
| Shared scale              | FP8 (E4M3)                                   | E8M0 (8-bit exponent, no mantissa)        |
| Per-tensor normalization  | âœ… FP32 (E8M23)                               | âŒ No                                      |
| Accuracy vs FP8           | âœ… Comparable                                | âš ï¸ Slightly lower, especially for large models |
| Use cases                 | LLMs, Vision Transformers, Low-precision inference | MatMul, Dot-Product in compute-in-memory |
| Hardware support          | NVIDIA Blackwell Tensor Cores                | Custom / research                          |

---

### ğŸ” Design Highlights

- ğŸ§® **Hierarchical scaling**: Combines FP8-level local scaling with global FP32 normalization
- ğŸ”¬ **Robust to outliers**: Smaller scale group (16 vs 32) reduces quantization errors from outliers
- âš¡ **Energy-efficient**: Up to **50Ã— energy savings** over FP8 with minimal accuracy loss
- ğŸ§  **LLM-ready**: Proven to maintain accuracy in large language models like GPT, LLaMA, and Stable Diffusion

> ğŸ“„ Reference: [NVIDIA Developer Blog â€” Introducing NVFP4](https://developer.nvidia.com/blog/introducing-nvfp4-for-efficient-and-accurate-low-precision-inference/)

---


## ğŸ§© Module Pipeline Strategy

content = """# p_TOP_Til_Dep_total_piped íŒŒì´í”„ë¼ì¸ ìŠ¤í…Œì´ì§€ ì •ë¦¬

`p_TOP_Til_Dep_total_piped` ëª¨ë“ˆì˜ íŒŒì´í”„ë¼ì¸ êµ¬ì¡°ë¥¼ **ìŠ¤í…Œì´ì§€ë³„(S1â†’S12)** ë¡œ ì •ë¦¬í•œ ê²ƒì´ë‹¤.  
í•µì‹¬ì€ **ìµœì¢… ì¶œë ¥(`io.out`)ì€ í•­ìƒ S12ì—ì„œ ë‚˜ì˜¤ë©°**, ê° depthì—ì„œì˜ ë³€í™˜ ê²°ê³¼ëŠ” í•´ë‹¹ ìŠ¤í…Œì´ì§€ì—ì„œ ì‚°ì¶œëœ ë’¤ **S12ê¹Œì§€ ë ˆì§€ìŠ¤í„°ë¡œ ë°€ì–´ ë‹¨ì¼ ìŠ¤ìœ„ì¹˜ì—ì„œ ì„ íƒ**ëœë‹¤ëŠ” ì ì´ë‹¤.

---

## S1 â€” Multiply & ScaleSum (â†’ Reg)
- ì—°ì‚°
  - `p_Multiplier`: 256ìŒì˜ MXFP4 â†’ `(sign, exponent, mantissa)` ë²¡í„°
  - `p_Adder_ScaleSum`: ê·¸ë£¹(8ê°œ)ë³„ `a_scale + b_scale` ë° `nan` í”Œë˜ê·¸ ê³„ì‚°
- ë ˆì§€ìŠ¤í„°ë§(ë‹¤ìŒ ìŠ¤í…Œì´ì§€ì— ì „ë‹¬)
  - `s1_sign`, `s1_exponent`, `s1_mantissa`, `s1_scale_sum`, `s1_scale_nan`
- depth íŒŒì´í”„
  - `depth_s1 = RegNext(io.depth)`

---

## S2 â€” In-group Expansion & (Emax + Scale) (â†’ Reg)
- ì—°ì‚°
  - 8ê°œì˜ `p_Expansion` ì¸ìŠ¤í„´ìŠ¤: ê° 32ìš”ì†Œ ê·¸ë£¹ ì •ë ¬/í™•ì¥, ê·¸ë£¹ë³„ `out_exponent_gmax(0)` ì‚°ì¶œ
  - `p_Adder_ScaleEmax`: `emax + scale_sum` â†’ **exp_cand**(ê·¸ë£¹ë³„ ë³€í™˜ ê¸°ì¤€ ì§€ìˆ˜), ê·¸ë¦¬ê³  `nan`
- ë ˆì§€ìŠ¤í„°ë§
  - `s2_exp_cand := RegNext(scaleEmax.io.out)`  
  - `s2_nan_flag := RegNext(scaleEmax.io.nan)`
  - `adder1(i)` ì…ë ¥ì€ `RegNext(expansion.io.out_*)`ë¥¼ í†µí•´ S3ì—ì„œ ì‚¬ìš©
- depth íŒŒì´í”„
  - `depth_s2 = RegNext(depth_s1)`

---

## S3 â€” (depth=0) Convert0 | else Adder1 (â†’ Reg)
- ë³€í™˜ ê²½ë¡œ(depth=0ìš©)
  - `p_MulConvert` ì…ë ¥: S1 ê²°ê³¼ë¥¼ `delayToStage(1â†’3)`ë¡œ **ë‘ ì‚¬ì´í´ ì§€ì—°**í•˜ì—¬ ì •ë ¬  
    (`toS3_sign/exp/man`, `toS3_scale_sum/nan`)
- ëˆ„ì‚° ê²½ë¡œ
  - 8ê°œì˜ `p_Adder_Dep_1` ê²°ê³¼ë¥¼ `s3_adder1_out := RegNextVec(...)`
- depth íŒŒì´í”„
  - `depth_s3 = RegNext(depth_s2)`

---

## S4 â€” (depth=1) Convert1 | else Adder2 (â†’ Reg)
- ë³€í™˜ ê²½ë¡œ(depth=1ìš©)
  - `convert1.io.in`: `s3_adder1_out` (8Ã—16=128ìš”ì†Œ) í‰íƒ„í™” ë§¤í•‘
  - `exp_cand/nan`: `delayToStage(3â†’4)`ë¡œ 1ì‚¬ì´í´ ì •ë ¬
- ëˆ„ì‚° ê²½ë¡œ
  - 8ê°œì˜ `p_Adder_Dep_2` ì…ë ¥ì— `s3_adder1_out` ì—°ê²°, ê²°ê³¼ `s4_adder2_out := RegNextVec(...)`
- depth íŒŒì´í”„
  - `depth_s4 = RegNext(depth_s3)`

---

## S5 â€” (depth=2) Convert2 | else Adder3 (â†’ Reg)
- ë³€í™˜ ê²½ë¡œ(depth=2ìš©)
  - `convert2.io.in`: `s4_adder2_out` (8Ã—8=64ìš”ì†Œ)
  - `exp_cand/nan`: `delayToStage(3â†’5)`ë¡œ 2ì‚¬ì´í´ ì •ë ¬
- ëˆ„ì‚° ê²½ë¡œ
  - 8ê°œì˜ `p_Adder_Dep_3` â†’ `s5_adder3_out := RegNextVec(...)`
- depth íŒŒì´í”„
  - `depth_s5 = RegNext(depth_s4)`

---

## S6 â€” (depth=3) Convert3 | else Adder4 (â†’ Reg)
- ë³€í™˜ ê²½ë¡œ(depth=3ìš©)
  - `convert3.io.in`: `s5_adder3_out` (8Ã—4=32ìš”ì†Œ)
  - `exp_cand/nan`: `delayToStage(3â†’6)`
- ëˆ„ì‚° ê²½ë¡œ
  - 8ê°œì˜ `p_Adder_Dep_4` â†’ `s6_adder4_out := RegNextVec(...)`
- depth íŒŒì´í”„
  - `depth_s6 = RegNext(depth_s5)`

---

## S7 â€” (depth=4) Convert4 | else Adder5 (â†’ Reg)
- ë³€í™˜ ê²½ë¡œ(depth=4ìš©)
  - `convert4.io.in`: `s6_adder4_out` (8Ã—2=16ìš”ì†Œ)
  - `exp_cand/nan`: `delayToStage(3â†’7)`
- ëˆ„ì‚° ê²½ë¡œ
  - 8ê°œì˜ `p_Adder_Dep_5` â†’ `s7_adder5_out := VecInit(RegNext(...))`
- depth íŒŒì´í”„
  - `depth_s7 = RegNext(depth_s6)`

---

## S8 â€” (depth=5) Convert5 | else Groupwise Expansion (â†’ Reg)
- ë³€í™˜ ê²½ë¡œ(depth=5ìš©)
  - `convert5.io.in`: `s7_adder5_out` (8ìš”ì†Œ)
  - `exp_cand/nan`: `delayToStage(3â†’8)`
- ê·¸ë£¹ì™€ì´ì¦ˆ ê²½ë¡œ(â‰¥6ì„ ìœ„í•œ ì¤€ë¹„)
  - `p_Expansion_Groupwise(5,30)`ì— `s7_adder5_out` + `toS8_exp_cand`(ê·¸ë£¹ ê¸°ì¤€ ì§€ìˆ˜) ì…ë ¥  
  - ê²°ê³¼ ë ˆì§€ìŠ¤í„°:  
    - `s8_gw_sign := RegNext(out_sign)`  
    - `s8_gw_mantissa := RegNext(out_mantissa)`  
    - `s8_gw_emax := RegNext(out_exponent_gmax)`  
  - `p_NaN_Process(5)`ì— `toS8_nan` ì…ë ¥ â†’ `s8_nan_proc := RegNext(result_nan)`
- depth íŒŒì´í”„
  - `depth_s8 = RegNext(depth_s7)`

---

## S9 â€” Adder_Groupwise_6 (â†’ Reg)
- ëˆ„ì‚° ê²½ë¡œ
  - `p_Adder_Groupwise(6,30)`ì— `s8_gw_*` ì…ë ¥ â†’  
    `s9_ad6_sign := RegNext(out_sign)`, `s9_ad6_mantissa := RegNext(out_mantissa)`
- depth íŒŒì´í”„
  - `depth_s9 = RegNext(depth_s8)`

---

## S10 â€” (depth=6) Convert_GW_6 | else Adder_Groupwise_7 (â†’ Reg)
- ë³€í™˜ ê²½ë¡œ(depth=6ìš©)
  - `convert_groupwise_6`ì— `s9_ad6_*` + `toS10_gw_emax := delayToStage(9â†’10, s8_gw_emax)` + `toS10_nan := delayToStage(9â†’10, s8_nan_proc)`
- ëˆ„ì‚° ê²½ë¡œ
  - `p_Adder_Groupwise(7,30)` â†’  
    `s10_ad7_sign := RegNext(...)`, `s10_ad7_mantissa := RegNext(...)`
- depth íŒŒì´í”„
  - `depth_s10 = RegNext(depth_s9)`

---

## S11 â€” (depth=7) Convert_GW_7 | else Adder_Groupwise_8 (â†’ Reg)
- ë³€í™˜ ê²½ë¡œ(depth=7ìš©)
  - `convert_groupwise_7`ì— `s10_ad7_*` + `toS11_gw_emax := delayToStage(9â†’11, s8_gw_emax)` + `toS11_nan := delayToStage(9â†’11, s8_nan_proc)`
- ëˆ„ì‚° ê²½ë¡œ
  - `p_Adder_Groupwise(8,30)` â†’  
    `s11_ad8_sign := RegNext(...)`, `s11_ad8_mantissa := RegNext(...)`
- depth íŒŒì´í”„
  - `depth_s11 = RegNext(depth_s10)`

---

## S12 â€” (depth=8) Convert_GW_8 (ìµœì¢… ë³€í™˜/ì„ íƒ)
- ë³€í™˜ ê²½ë¡œ(depth=8ìš©)
  - `convert_groupwise_8`ì— `s11_ad8_*` + `toS12_gw_emax := delayToStage(9â†’12, s8_gw_emax)` + `toS12_nan := delayToStage(9â†’12, s8_nan_proc)`
- **ë‹¨ì¼ ì„ íƒ ì§€ì **
  - ëª¨ë“  depthë³„ ë³€í™˜ ì¶œë ¥ì„ **S12ë¡œ ì •ë ¬**:
    - `d0_atS12 = pipeVecN(convert0, 9)`  (S3â†’S12)
    - `d1_atS12 = pipeVecN(convert1, 8)`  (S4â†’S12)
    - `d2_atS12 = pipeVecN(convert2, 7)`  (S5â†’S12)
    - `d3_atS12 = pipeVecN(convert3, 6)`  (S6â†’S12)
    - `d4_atS12 = pipeVecN(convert4, 5)`  (S7â†’S12)
    - `d5_atS12 = pipeVecN(convert5, 4)`  (S8â†’S12)
    - `d6_atS12 = pipeVecN(conv_gw6, 2)`  (S10â†’S12)
    - `d7_atS12 = pipeVecN(conv_gw7, 1)`  (S11â†’S12)
    - `d8_atS12 = conv_gw8`               (S12)
  - ê° ë²¡í„°ëŠ” `padTo16`ìœ¼ë¡œ 16í¬íŠ¸ì— zero-pad í›„, `switch(depth_s12)`ë¡œ `io.out` ì„ íƒ
- depth íŒŒì´í”„
  - `depth_s12 = RegNext(depth_s11)`

---

## ê¹Šì´ë³„(Depth) â€œì‹¤ì œ ë³€í™˜ ì‹œì â€ê³¼ ì •ë ¬
- ë³€í™˜ì´ ì²˜ìŒ ë°œìƒí•˜ëŠ” ìŠ¤í…Œì´ì§€
  - **D0**: S3, **D1**: S4, **D2**: S5, **D3**: S6, **D4**: S7, **D5**: S8, **D6**: S10, **D7**: S11, **D8**: S12
- ê·¸ëŸ¬ë‚˜ ìµœì¢… ì¶œë ¥ì€ í•­ìƒ **S12**ì—ì„œ ì„ íƒ â†’ ëª¨ë“  ë³€í™˜ ê²°ê³¼ëŠ” **pipeVecN**ìœ¼ë¡œ S12ê¹Œì§€ ì§€ì—° ì •ë ¬

---

## exp/nan ì •ë ¬ ê·œì¹™(í•­ìƒ ë³€í™˜ ìŠ¤í…Œì´ì§€ì— ë§ì¶° ì •ë ¬)
- `s2_exp_cand`, `s2_nan_flag`ë¥¼ ê¸°ì¤€ìœ¼ë¡œ:
  - D0: S1â†’S3 ì •ë ¬(`toS3_*`)
  - D1: S3â†’S4 ì •ë ¬(`toS4_*`)
  - D2: S3â†’S5 ì •ë ¬(`toS5_*`)
  - D3: S3â†’S6 ì •ë ¬(`toS6_*`)
  - D4: S3â†’S7 ì •ë ¬(`toS7_*`)
  - D5: S3â†’S8 ì •ë ¬(`toS8_*`)
- ê·¸ë£¹ì™€ì´ì¦ˆ(â‰¥6):
  - S8ì—ì„œ `s8_gw_emax`, `s8_nan_proc`ë¥¼ ë§Œë“  ë’¤,
  - D6:  S8â†’S10 (`toS10_*`)
  - D7:  S8â†’S11 (`toS11_*`)
  - D8:  S8â†’S12 (`toS12_*`)

---

## ìš”ì†Œ ìˆ˜ ë³€í™”(ê°œëµ)
- Mul/Exp ì´í›„: 256  
- Adder1: 128 â†’ Adder2: 64 â†’ Adder3: 32 â†’ Adder4: 16 â†’ Adder5: 8  
- Groupwise Adder6: 4 â†’ Adder7: 2 â†’ Adder8: 1  
- Convert ì‹œì ì˜ ì¶œë ¥ì€ í•­ìƒ **16í¬íŠ¸ë¡œ íŒ¨ë”©**ë˜ì–´ `io.out(16)`ì—ì„œ í†µì¼

---

## ë””ë²„ê·¸ í¬íŠ¸
- `adder6_out_*`: S9 ê²°ê³¼(ë ˆì§€ìŠ¤í„° í›„ ë°°ì„ )  
- `adder7_out_*`: S10 ê²°ê³¼  
- `adder8_out_*`: S11 ê²°ê³¼  
â†’ Groupwise ë‹¨ê³„ì˜ ë‚´ë¶€ ëˆ„ì‚° ê°’ì„ ì™¸ë¶€ì—ì„œ ê´€ì°° ê°€ëŠ¥

---

## ìš”ì•½ ë©”ëª¨
- **ë‹¨ì¼ latency ì •ì±…**: ì–´ë–¤ depthë“  **S12 ê³ ì • ì¶œë ¥** â†’ íƒ€ì´ë° ìˆ˜ì›”, ì¸í„°í˜ì´ìŠ¤ ë‹¨ìˆœí™”  
- **ì •ë ¬ í•µì‹¬**: `delayToStage(from, to, vec)`/`pipeVecN`ìœ¼ë¡œ **exp/nan/ë°ì´í„°**ë¥¼ ë³€í™˜ ìŠ¤í…Œì´ì§€ì™€ ìµœì¢… S12ì— **ì •í™•íˆ ì •ë ¬**  
- **â‰¥6ì—ì„œì˜ ë¶„ê¸°**: S8ì—ì„œ ê·¸ë£¹ì™€ì´ì¦ˆ ë„ë©”ì¸ìœ¼ë¡œ ì „í™˜(ë¶€í˜¸/ê°€ìˆ˜/ê·¸ë£¹ emax/NaN ì¬í¸ì„±), ì´í›„ D6~D8 ë³€í™˜ê¸° ì‚¬ìš©
""" 


---

## ğŸ› ï¸ How to Build

Run the following command to generate Verilog using `sbt`:

```bash
run build <ModuleName>
```
## ğŸ§ª Test (with cocotb)
Each module is testable using Python-based cocotb. 

Example:
```bash
run cotb <ModuleName>
```

```bash
src/
 â””â”€â”€ main/
      â””â”€â”€ scala/
           â””â”€â”€ mxfp4/
                â”œâ”€â”€ FieldExtractor.scala
                â”œâ”€â”€ piped/
                â”‚    â”œâ”€â”€ p_Multiplier.scala
                â”‚    â”œâ”€â”€ p_MulConvert.scala
                â”‚    â”œâ”€â”€ p_Adder.scala
generated/
 â””â”€â”€ verilog/
cocotb/
 â””â”€â”€ tb_Multiplier.py
```
ğŸ§  Author
Designed by Wonjun Han[AI Chip Arhictect] - Furiosa AI


